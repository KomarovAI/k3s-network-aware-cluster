# Optimized Monitoring Stack for VPS Master + Home PC Workers
# Minimizes network traffic between nodes through local aggregation

apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
    optimization: network-aware
---
# Lightweight Prometheus for VPS (receives aggregated metrics)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-master
  namespace: monitoring
  labels:
    app: prometheus
    tier: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
      tier: master
  template:
    metadata:
      labels:
        app: prometheus
        tier: master
      annotations:
        network.komarov.dev/data-locality: "low"  # Receives remote data
        network.komarov.dev/compression: "gzip"
    spec:
      schedulerName: network-aware-scheduler
      
      # Force scheduling on VPS master
      nodeSelector:
        node-type: vps
        role: master
      
      tolerations:
      - key: k3s-controlplane
        operator: Equal
        value: "true"
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      
      containers:
      - name: prometheus
        image: prom/prometheus:v2.47.0
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus/'
          - '--web.console.libraries=/etc/prometheus/console_libraries'
          - '--web.console.templates=/etc/prometheus/consoles'
          - '--storage.tsdb.retention.time=24h'  # Short retention for VPS
          - '--storage.tsdb.retention.size=5GB'   # Limit storage usage
          - '--web.enable-lifecycle'
          - '--web.enable-admin-api'
          - '--query.max-concurrency=10'  # Limit concurrent queries
          - '--query.max-samples=1000000' # Limit sample processing
        ports:
        - containerPort: 9090
          name: web
        resources:
          requests:
            memory: "400Mi"
            cpu: "200m"
          limits:
            memory: "800Mi"
            cpu: "500m"
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: storage
          mountPath: /prometheus
        
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9090
          initialDelaySeconds: 30
          periodSeconds: 15
        
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9090
          initialDelaySeconds: 5
          periodSeconds: 5
      
      volumes:
      - name: config
        configMap:
          name: prometheus-master-config
      - name: storage
        persistentVolumeClaim:
          claimName: prometheus-master-pvc
---
# Prometheus configuration for master (receives aggregated data)
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-master-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 60s      # Longer intervals to reduce network load
      evaluation_interval: 60s
      external_labels:
        cluster: 'k3s-network-aware'
        region: 'vps-master'
    
    rule_files:
      - "/etc/prometheus/rules/*.yml"
    
    scrape_configs:
    # Scrape aggregated metrics from home PC nodes
    - job_name: 'home-pc-aggregated'
      scrape_interval: 60s
      metrics_path: '/federate'
      params:
        'match[]':
          - '{__name__=~"up|node_.*|container_.*|kubelet_.*"}'
          - '{__name__=~".*_total|.*_count|.*_sum"}'
      static_configs:
      - targets:
        - 'prometheus-worker.monitoring.svc.cluster.local:9090'
      metric_relabel_configs:
      # Compress metric names to reduce bandwidth
      - source_labels: [__name__]
        regex: 'container_(.*)'
        target_label: __name__
        replacement: 'c_${1}'
      - source_labels: [__name__]
        regex: 'node_(.*)'
        target_label: __name__
        replacement: 'n_${1}'
    
    # Local VPS metrics (minimal)
    - job_name: 'vps-local'
      scrape_interval: 30s
      static_configs:
      - targets: ['localhost:9100']
        labels:
          node_type: 'vps'
          zone: 'remote'
    
    # K3S API server metrics (compressed)
    - job_name: 'k3s-apiserver'
      scrape_interval: 60s
      static_configs:
      - targets: ['localhost:6443']
        labels:
          component: 'apiserver'
      bearer_token_file: '/var/run/secrets/kubernetes.io/serviceaccount/token'
      tls_config:
        ca_file: '/var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
        insecure_skip_verify: true
    
    # Remote write to reduce local storage (optional)
    # remote_write:
    # - url: "https://metrics-collector.external/api/v1/write"
    #   queue_config:
    #     batch_send_deadline: 30s
    #     min_shards: 1
    #     max_shards: 3
---
# Home PC Prometheus Aggregator (DaemonSet)
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: prometheus-worker-aggregator
  namespace: monitoring
  labels:
    app: prometheus-worker
    tier: aggregator
spec:
  selector:
    matchLabels:
      app: prometheus-worker
      tier: aggregator
  template:
    metadata:
      labels:
        app: prometheus-worker
        tier: aggregator
      annotations:
        network.komarov.dev/data-locality: "high"  # Local data collection
        network.komarov.dev/compression: "gzip"
    spec:
      schedulerName: network-aware-scheduler
      
      # Only schedule on home PC workers
      nodeSelector:
        node-type: home-pc
        compute-tier: workload
      
      # Avoid VPS master
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: NotIn
                values: ["vps"]
      
      hostNetwork: true
      hostPID: true
      
      containers:
      - name: prometheus
        image: prom/prometheus:v2.47.0
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus/'
          - '--storage.tsdb.retention.time=2h'    # Short local retention
          - '--storage.tsdb.retention.size=1GB'
          - '--web.listen-address=0.0.0.0:9090'
          - '--web.enable-lifecycle'
          - '--web.enable-admin-api'
          - '--query.max-concurrency=5'   # Lower for worker nodes
        ports:
        - containerPort: 9090
          name: web
          hostPort: 9090
        resources:
          requests:
            memory: "200Mi"
            cpu: "100m"
          limits:
            memory: "500Mi"
            cpu: "300m"
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: storage
          mountPath: /prometheus
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
      
      - name: node-exporter
        image: prom/node-exporter:v1.6.1
        args:
          - '--path.procfs=/host/proc'
          - '--path.sysfs=/host/sys'
          - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|\\\/)'  
        ports:
        - containerPort: 9100
          name: metrics
          hostPort: 9100
        resources:
          requests:
            memory: "50Mi"
            cpu: "50m"
          limits:
            memory: "100Mi"
            cpu: "100m"
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
      
      volumes:
      - name: config
        configMap:
          name: prometheus-worker-config
      - name: storage
        emptyDir:
          sizeLimit: 2Gi
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
---
# Worker Prometheus configuration (local collection + aggregation)
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-worker-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s      # High frequency for local collection
      evaluation_interval: 15s
      external_labels:
        zone: 'local'
        node_name: '${HOSTNAME}'
    
    scrape_configs:
    # Local node metrics
    - job_name: 'node-exporter'
      scrape_interval: 15s
      static_configs:
      - targets: ['localhost:9100']
        labels:
          node_type: 'home-pc'
          zone: 'local'
    
    # Local kubelet metrics
    - job_name: 'kubelet'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: node
        namespaces:
          names: []
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics
    
    # cAdvisor metrics for containers
    - job_name: 'cadvisor'
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
      
      # Metric relabeling to reduce data size
      metric_relabel_configs:
      # Keep only essential container metrics
      - source_labels: [__name__]
        regex: 'container_(cpu_usage_seconds_total|memory_usage_bytes|network_.*_bytes_total|fs_.*_bytes)'
        action: keep
---
# Grafana deployment (on VPS for external access)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
      annotations:
        network.komarov.dev/compression: "brotli"
    spec:
      schedulerName: network-aware-scheduler
      
      # Schedule on VPS for external access
      nodeSelector:
        node-type: vps
        role: master
      
      tolerations:
      - key: k3s-controlplane
        operator: Equal
        value: "true"
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      
      containers:
      - name: grafana
        image: grafana/grafana:10.1.0
        ports:
        - containerPort: 3000
          name: web
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          value: "admin123"
        - name: GF_INSTALL_PLUGINS
          value: "grafana-piechart-panel"
        - name: GF_SERVER_ROOT_URL
          value: "http://grafana.komarov.local"
        
        # Optimization for VPS resources
        - name: GF_DATABASE_MAX_IDLE_CONN
          value: "5"
        - name: GF_DATABASE_MAX_OPEN_CONN
          value: "10"
        - name: GF_SERVER_ENABLE_GZIP
          value: "true"
        
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
          limits:
            memory: "300Mi"
            cpu: "300m"
        
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-config
          mountPath: /etc/grafana/provisioning
      
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-pvc
      - name: grafana-config
        configMap:
          name: grafana-config
---
# Services
apiVersion: v1
kind: Service
metadata:
  name: prometheus-master
  namespace: monitoring
spec:
  selector:
    app: prometheus
    tier: master
  ports:
  - port: 9090
    targetPort: 9090
    name: web
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
spec:
  selector:
    app: grafana
  ports:
  - port: 3000
    targetPort: 3000
    name: web
---
# PVCs
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-master-pvc
  namespace: monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: local-path
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-pvc
  namespace: monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
  storageClassName: local-path