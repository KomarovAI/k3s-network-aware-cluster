#!/usr/bin/env python3
"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è K3S –∫–ª–∞—Å—Ç–µ—Ä–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º
–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –º–µ–∂–¥—É master (VPS) –∏ worker (Home PC) –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç:
- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ—Å—Ç–∞—é—Ç—Å—è –Ω–∞ master VPS
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è –Ω–∞ worker Home PC
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ resource limits –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–æ–¥—ã
- Proper node selectors –∏ tolerations

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python3 scripts/deploy_all_optimized.py --domain cockpit.work.gd --email artur.komarovv@gmail.com --gpu true

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
  sudo apt-get update && sudo apt-get install -y curl jq python3 python3-yaml gettext-base
  curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
"""

import argparse
import json
import os
import subprocess
import sys
import time
import yaml
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

REPO_ROOT = Path(__file__).resolve().parents[1]
REQUIRED_TOOLS = ['kubectl', 'curl', 'jq', 'envsubst', 'helm']

class OptimizedClusterDeployer:
    def __init__(self, domain: str, email: str, enable_gpu: bool, use_dns01: bool):
        self.domain = domain
        self.email = email
        self.enable_gpu = enable_gpu
        self.use_dns01 = use_dns01
        self.master_node = None
        self.worker_nodes = []
        
    def log_info(self, msg: str):
        print(f"‚ÑπÔ∏è  {msg}")
    
    def log_success(self, msg: str):
        print(f"‚úÖ {msg}")
    
    def log_error(self, msg: str):
        print(f"‚ùå {msg}")
    
    def log_warning(self, msg: str):
        print(f"‚ö†Ô∏è  {msg}")
        
    def run_kubectl(self, cmd: str, capture_output=True, check=True) -> subprocess.CompletedProcess:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ kubectl –∫–æ–º–∞–Ω–¥—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        full_cmd = f"kubectl {cmd}"
        if not capture_output:
            print(f"$ {full_cmd}")
        return subprocess.run(full_cmd, shell=True, capture_output=capture_output, text=True, check=check)
    
    def wait_for_condition(self, cmd: str, success_msg: str, timeout: int = 300, sleep_interval: float = 5.0) -> bool:
        """–£–º–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º backoff"""
        self.log_info(f"–û–∂–∏–¥–∞–Ω–∏–µ: {success_msg}")
        start_time = time.time()
        attempts = 0
        
        while time.time() - start_time < timeout:
            try:
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                if result.returncode == 0:
                    self.log_success(success_msg)
                    return True
            except Exception as e:
                self.log_warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempts + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            
            attempts += 1
            wait_time = min(sleep_interval * (1.5 ** (attempts // 3)), 30)
            time.sleep(wait_time)
        
        self.log_error(f"–¢–∞–π–º–∞—É—Ç ({timeout}s) –ø—Ä–∏ –æ–∂–∏–¥–∞–Ω–∏–∏: {success_msg}")
        return False
    
    def check_dependencies(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        self.log_info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
        missing = []
        
        for tool in REQUIRED_TOOLS:
            result = subprocess.run(f"which {tool}", shell=True, capture_output=True)
            if result.returncode != 0:
                missing.append(tool)
        
        if missing:
            self.log_error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: {', '.join(missing)}")
            self.log_info("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö –∫–æ–º–∞–Ω–¥–æ–π:")
            if 'helm' in missing:
                print("curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash")
            if any(tool in ['curl', 'jq', 'gettext-base'] for tool in missing):
                print("sudo apt-get update && sudo apt-get install -y curl jq gettext-base")
            return False
        
        self.log_success("–í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω—ã")
        return True
    
    def analyze_cluster_topology(self) -> bool:
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è"""
        self.log_info("–ê–Ω–∞–ª–∏–∑ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞...")
        
        try:
            result = self.run_kubectl("get nodes -o json")
            nodes_data = json.loads(result.stdout)
            
            for node in nodes_data['items']:
                node_name = node['metadata']['name']
                labels = node['metadata'].get('labels', {})
                
                if any(label.startswith('node-role.kubernetes.io/control-plane') for label in labels.keys()):
                    self.master_node = node_name
                    self.log_info(f"Master –Ω–æ–¥–∞: {node_name}")
                else:
                    self.worker_nodes.append(node_name)
                    self.log_info(f"Worker –Ω–æ–¥–∞: {node_name}")
            
            if not self.master_node:
                self.log_error("Master –Ω–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
                
            if not self.worker_nodes:
                self.log_warning("Worker –Ω–æ–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ—Å—Ç–∞–Ω—É—Ç—Å—è –Ω–∞ master.")
            else:
                self.log_success(f"–ù–∞–π–¥–µ–Ω–æ worker –Ω–æ–¥: {len(self.worker_nodes)}")
            
            return True
            
        except Exception as e:
            self.log_error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–ø–æ–ª–æ–≥–∏–∏: {e}")
            return False
    
    def deploy_master_components(self) -> bool:
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –î–û–õ–ñ–ù–´ –æ—Å—Ç–∞—Ç—å—Å—è –Ω–∞ master"""
        self.log_info("–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞ master...")
        
        if not self.wait_for_condition("kubectl get nodes", "–ö–ª–∞—Å—Ç–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é"):
            return False
        
        # 1. ingress-nginx (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –Ω–∞ master –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞)
        self.log_info("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ ingress-nginx –Ω–∞ master...")
        subprocess.run([
            "kubectl", "apply", "-f",
            "https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.10.0/deploy/static/provider/cloud/deploy.yaml"
        ])
        
        # –ü—Ä–∏–Ω—É–∂–¥–∞–µ–º ingress-nginx –æ—Å—Ç–∞—Ç—å—Å—è –Ω–∞ master
        if not self.wait_for_condition(
            "kubectl -n ingress-nginx get deployment ingress-nginx-controller",
            "ingress-nginx deployment —Å–æ–∑–¥–∞–Ω"
        ):
            return False
            
        # –î–æ–±–∞–≤–ª—è–µ–º nodeSelector –∏ tolerations –¥–ª—è master
        ingress_patch = {
            "spec": {
                "template": {
                    "spec": {
                        "nodeSelector": {
                            "node-role.kubernetes.io/control-plane": "true"
                        },
                        "tolerations": [
                            {
                                "key": "node-role.kubernetes.io/control-plane",
                                "operator": "Exists",
                                "effect": "NoSchedule"
                            }
                        ]
                    }
                }
            }
        }
        
        subprocess.run([
            "kubectl", "patch", "deployment", "ingress-nginx-controller",
            "-n", "ingress-nginx", "--patch", json.dumps(ingress_patch)
        ])
        
        if not self.wait_for_condition(
            "kubectl -n ingress-nginx rollout status deploy/ingress-nginx-controller --timeout=300s",
            "ingress-nginx –≥–æ—Ç–æ–≤ –Ω–∞ master"
        ):
            return False
        
        # 2. cert-manager (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –Ω–∞ master –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞–º–∏)
        self.log_info("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ cert-manager –Ω–∞ master...")
        subprocess.run(["kubectl", "apply", "-f", "https://github.com/cert-manager/cert-manager/releases/download/v1.15.3/cert-manager.crds.yaml"])
        subprocess.run(["kubectl", "create", "namespace", "cert-manager", "--dry-run=client", "-o", "yaml"], 
                      stdout=subprocess.PIPE, shell=False) # –°–æ–∑–¥–∞–µ–º namespace
        subprocess.run(["kubectl", "apply", "-f"], input=subprocess.run(["kubectl", "create", "namespace", "cert-manager", "--dry-run=client", "-o", "yaml"], 
                      capture_output=True, text=True).stdout, text=True)
        
        subprocess.run(["kubectl", "apply", "-f", "https://github.com/cert-manager/cert-manager/releases/download/v1.15.3/cert-manager.yaml"])
        
        if not self.wait_for_condition(
            "kubectl -n cert-manager rollout status deploy/cert-manager --timeout=300s",
            "cert-manager –≥–æ—Ç–æ–≤"
        ):
            return False
        
        # üîß –í–ê–ñ–ù–û: –ü—Ä–∏–Ω—É–∂–¥–∞–µ–º cert-manager –æ—Å—Ç–∞—Ç—å—Å—è –Ω–∞ master VPS
        self.log_info("–ó–∞–∫—Ä–µ–ø–ª–µ–Ω–∏–µ cert-manager –Ω–∞ master VPS...")
        cert_manager_deployments = [
            "cert-manager",
            "cert-manager-cainjector", 
            "cert-manager-webhook"
        ]
        
        cert_manager_patch = {
            "spec": {
                "template": {
                    "spec": {
                        "nodeSelector": {
                            "node-role.kubernetes.io/control-plane": "true"
                        },
                        "tolerations": [
                            {
                                "key": "node-role.kubernetes.io/control-plane",
                                "operator": "Exists",
                                "effect": "NoSchedule"
                            }
                        ]
                    }
                }
            }
        }
        
        for deployment in cert_manager_deployments:
            try:
                subprocess.run([
                    "kubectl", "patch", "deployment", deployment,
                    "-n", "cert-manager", "--patch", json.dumps(cert_manager_patch)
                ], check=True)
                self.log_success(f"cert-manager {deployment} –∑–∞–∫—Ä–µ–ø–ª–µ–Ω –Ω–∞ master")
            except subprocess.CalledProcessError:
                self.log_warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∫—Ä–µ–ø–∏—Ç—å {deployment} –Ω–∞ master (–≤–æ–∑–º–æ–∂–Ω–æ, –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤)")
        
        # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ cert-manager —Å –Ω–æ–≤—ã–º–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
        time.sleep(30)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ cert-manager –≥–æ—Ç–æ–≤ –ø–æ—Å–ª–µ –ø–∞—Ç—á–∏–Ω–≥–∞
        if not self.wait_for_condition(
            "kubectl -n cert-manager rollout status deploy/cert-manager --timeout=180s",
            "cert-manager –≥–æ—Ç–æ–≤ –ø–æ—Å–ª–µ –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∏—è –Ω–∞ master"
        ):
            self.log_warning("cert-manager –º–µ–¥–ª–µ–Ω–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º ClusterIssuer
        self.apply_cluster_issuers()
        
        # 3. –ë–∞–∑–æ–≤—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞
        base_dir = REPO_ROOT / "manifests/base"
        if base_dir.exists():
            self.run_kubectl(f"apply -k {base_dir}", capture_output=False)
        
        return True
    
    def deploy_worker_components(self) -> bool:
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ worker"""
        if not self.worker_nodes:
            self.log_warning("Worker –Ω–æ–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Ä–∞–∑–º–µ—â–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–∞ master (—Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏)")
            return self.deploy_monitoring_on_master()
        
        self.log_info("–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞ worker –Ω–æ–¥–µ...")
        
        # –°–æ–∑–¥–∞–µ–º namespace –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        subprocess.run(["kubectl", "create", "namespace", "monitoring", "--dry-run=client", "-o", "yaml"], 
                      stdout=subprocess.PIPE) 
        subprocess.run(["kubectl", "apply", "-f", "-"], 
                      input=subprocess.run(["kubectl", "create", "namespace", "monitoring", "--dry-run=client", "-o", "yaml"], 
                                          capture_output=True, text=True).stdout, text=True)
        
        # 1. Registry Cache –Ω–∞ worker (—ç–∫–æ–Ω–æ–º–∏—Ç —Ç—Ä–∞—Ñ–∏–∫ –Ω–∞ master)
        self.deploy_registry_cache_on_worker()
        
        # 2. Prometheus –Ω–∞ worker (–æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å —Ä–µ—Å—É—Ä—Å–æ–≤)
        self.deploy_prometheus_on_worker()
        
        # 3. Grafana –Ω–∞ worker
        self.deploy_grafana_on_worker()
        
        # 4. Kubevious –Ω–∞ worker
        self.deploy_kubevious_on_worker()
        
        # 5. GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        if self.enable_gpu:
            self.deploy_gpu_monitoring_on_worker()
        
        return True
    
    def deploy_registry_cache_on_worker(self):
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ registry cache –Ω–∞ worker"""
        self.log_info("–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Registry Cache –Ω–∞ worker...")
        
        registry_manifest = f'''
apiVersion: apps/v1
kind: Deployment
metadata:
  name: registry-cache
  namespace: kube-system
  labels:
    app: registry-cache
spec:
  replicas: 1
  selector:
    matchLabels:
      app: registry-cache
  template:
    metadata:
      labels:
        app: registry-cache
    spec:
      nodeSelector:
        node-role.kubernetes.io/worker: "worker"
      containers:
      - name: registry
        image: registry:2.8
        env:
        - name: REGISTRY_PROXY_REMOTEURL
          value: "https://registry-1.docker.io"
        - name: REGISTRY_STORAGE_CACHE_BLOBDESCRIPTOR
          value: "inmemory"
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m  # –ë–æ–ª—å—à–µ –Ω–∞ worker
            memory: 256Mi
        ports:
        - containerPort: 5000
        volumeMounts:
        - name: cache-storage
          mountPath: /var/lib/registry
      volumes:
      - name: cache-storage
        emptyDir:
          sizeLimit: 20Gi  # –ë–æ–ª—å—à–µ –º–µ—Å—Ç–∞ –Ω–∞ worker
---
apiVersion: v1
kind: Service
metadata:
  name: registry-cache
  namespace: kube-system
spec:
  selector:
    app: registry-cache
  ports:
  - port: 5000
    targetPort: 5000
'''
        
        with open("/tmp/registry-cache-worker.yaml", "w") as f:
            f.write(registry_manifest)
        
        self.run_kubectl("apply -f /tmp/registry-cache-worker.yaml", capture_output=False)
        
        if self.wait_for_condition(
            "kubectl -n kube-system rollout status deployment/registry-cache --timeout=180s",
            "Registry Cache –≥–æ—Ç–æ–≤ –Ω–∞ worker"
        ):
            self.log_success("Registry Cache —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç –Ω–∞ worker")
    
    def deploy_prometheus_on_worker(self):
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Prometheus –Ω–∞ worker —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏"""
        self.log_info("–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Prometheus –Ω–∞ worker...")
        
        prometheus_manifest = f'''
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      nodeSelector:
        node-role.kubernetes.io/worker: "worker"
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.47.0
        args:
        - "--config.file=/etc/prometheus/prometheus.yml"
        - "--storage.tsdb.path=/prometheus"
        - "--storage.tsdb.retention.time=15d"  # 15 –¥–Ω–µ–π retention
        - "--web.console.libraries=/etc/prometheus/console_libraries"
        - "--web.console.templates=/etc/prometheus/consoles"
        - "--web.enable-lifecycle"
        - "--web.external-url=https://grafana.{self.domain}/prometheus"
        resources:
          requests:
            cpu: 500m    # –ë–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–∞ –º–æ—â–Ω–æ–º worker
            memory: 1Gi
          limits:
            cpu: 2000m   # –î–æ 2 CPU –Ω–∞ worker
            memory: 4Gi  # –î–æ 4GB RAM –Ω–∞ worker
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-storage
          mountPath: /prometheus
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        persistentVolumeClaim:
          claimName: prometheus-storage-worker
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-storage-worker
  namespace: monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi  # –ë–æ–ª—å—à–µ –º–µ—Å—Ç–∞ –Ω–∞ worker
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
spec:
  selector:
    app: prometheus
  ports:
  - port: 9090
    targetPort: 9090
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources: ["nodes", "services", "endpoints", "pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
'''
        
        with open("/tmp/prometheus-worker.yaml", "w") as f:
            f.write(prometheus_manifest)
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é Prometheus
        self.create_prometheus_config()
        
        self.run_kubectl("apply -f /tmp/prometheus-worker.yaml", capture_output=False)
        
        if self.wait_for_condition(
            "kubectl -n monitoring rollout status deployment/prometheus --timeout=300s",
            "Prometheus –≥–æ—Ç–æ–≤ –Ω–∞ worker",
            timeout=360
        ):
            self.log_success("Prometheus —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç –Ω–∞ worker —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏")
    
    def create_prometheus_config(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Prometheus –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞"""
        prometheus_config = '''
global:
  scrape_interval: 30s  # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω–æ–π —Å–≤—è–∑–∏
  evaluation_interval: 30s
  external_labels:
    cluster: 'k3s-hybrid-cluster'
    environment: 'production'

rule_files:
  - "*.rules.yml"

scrape_configs:
- job_name: 'kubernetes-apiservers'
  kubernetes_sd_configs:
  - role: endpoints
  scheme: https
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    insecure_skip_verify: true
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  relabel_configs:
  - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
    action: keep
    regex: default;kubernetes;https

- job_name: 'kubernetes-nodes'
  scheme: https
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    insecure_skip_verify: true
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  kubernetes_sd_configs:
  - role: node
  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)

- job_name: 'kubernetes-cadvisor'
  scheme: https
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    insecure_skip_verify: true
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  kubernetes_sd_configs:
  - role: node
  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)
  - target_label: __address__
    replacement: kubernetes.default.svc:443
  - source_labels: [__meta_kubernetes_node_name]
    regex: (.+)
    target_label: __metrics_path__
    replacement: /api/v1/nodes/\${1}/proxy/metrics/cadvisor

- job_name: 'kubernetes-pods'
  kubernetes_sd_configs:
  - role: pod
  relabel_configs:
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
    action: keep
    regex: true
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
    action: replace
    target_label: __metrics_path__
    regex: (.+)
'''
        
        config_map = {
            "apiVersion": "v1",
            "kind": "ConfigMap",
            "metadata": {
                "name": "prometheus-config",
                "namespace": "monitoring"
            },
            "data": {
                "prometheus.yml": prometheus_config.strip()
            }
        }
        
        with open("/tmp/prometheus-config.yaml", "w") as f:
            yaml.dump(config_map, f)
        
        self.run_kubectl("apply -f /tmp/prometheus-config.yaml", capture_output=False)
    
    def deploy_grafana_on_worker(self):
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Grafana –Ω–∞ worker"""
        self.log_info("–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Grafana –Ω–∞ worker...")
        
        grafana_manifest = f'''
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
  labels:
    app: grafana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      nodeSelector:
        node-role.kubernetes.io/worker: "worker"
      containers:
      - name: grafana
        image: grafana/grafana:10.1.0
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          value: "admin"  # –ò–∑–º–µ–Ω–∏—Ç–µ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–¥–∞
        - name: GF_USERS_ALLOW_SIGN_UP
          value: "false"
        - name: GF_SERVER_ROOT_URL
          value: "https://grafana.{self.domain}"
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 1000m  # –ë–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –Ω–∞ worker
            memory: 1Gi
        ports:
        - containerPort: 3000
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        - name: grafana-datasources
          mountPath: /etc/grafana/provisioning/datasources
        - name: grafana-dashboards-config
          mountPath: /etc/grafana/provisioning/dashboards
        - name: grafana-dashboards
          mountPath: /var/lib/grafana/dashboards
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-storage-worker
      - name: grafana-datasources
        configMap:
          name: grafana-datasource
      - name: grafana-dashboards-config
        configMap:
          name: grafana-dashboards-config
      - name: grafana-dashboards
        configMap:
          name: grafana-dashboards
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-storage-worker
  namespace: monitoring
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi  # –ë–æ–ª—å—à–µ –º–µ—Å—Ç–∞ –Ω–∞ worker
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
spec:
  selector:
    app: grafana
  ports:
  - port: 3000
    targetPort: 3000
'''
        
        with open("/tmp/grafana-worker.yaml", "w") as f:
            f.write(grafana_manifest)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º Grafana –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        monitoring_dir = REPO_ROOT / "manifests/monitoring"
        if monitoring_dir.exists():
            # Datasource
            datasource_file = monitoring_dir / "grafana-provisioning/datasource-configmap.yaml"
            if datasource_file.exists():
                self.run_kubectl(f"apply -f {datasource_file}", capture_output=False)
            
            # Dashboards
            dashboards_file = monitoring_dir / "grafana-provisioning/dashboards-configmap.yaml"
            if dashboards_file.exists():
                self.run_kubectl(f"apply -f {dashboards_file}", capture_output=False)
            
            provisioning_file = monitoring_dir / "grafana-provisioning/provisioning-wiring.yaml"
            if provisioning_file.exists():
                self.run_kubectl(f"apply -f {provisioning_file}", capture_output=False)
        
        self.run_kubectl("apply -f /tmp/grafana-worker.yaml", capture_output=False)
        
        if self.wait_for_condition(
            "kubectl -n monitoring rollout status deployment/grafana --timeout=180s",
            "Grafana –≥–æ—Ç–æ–≤–∞ –Ω–∞ worker"
        ):
            self.log_success("Grafana —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–∞ –Ω–∞ worker")
    
    def deploy_kubevious_on_worker(self):
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Kubevious –Ω–∞ worker"""
        self.log_info("–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ Kubevious –Ω–∞ worker...")
        
        # –°–æ–∑–¥–∞–µ–º namespace
        subprocess.run(["kubectl", "create", "namespace", "kubevious", "--dry-run=client", "-o", "yaml"], 
                      stdout=subprocess.PIPE)
        subprocess.run(["kubectl", "apply", "-f", "-"], 
                      input=subprocess.run(["kubectl", "create", "namespace", "kubevious", "--dry-run=client", "-o", "yaml"], 
                                          capture_output=True, text=True).stdout, text=True)
        
        # –î–æ–±–∞–≤–ª—è–µ–º Helm —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
        subprocess.run(["helm", "repo", "add", "kubevious", "https://helm.kubevious.io"])
        subprocess.run(["helm", "repo", "update"])
        
        # –°–æ–∑–¥–∞–µ–º values —Ñ–∞–π–ª –¥–ª—è worker —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
        kubevious_values = f'''
# –†–∞–∑–º–µ—â–µ–Ω–∏–µ –Ω–∞ worker –Ω–æ–¥–µ
nodeSelector:
  node-role.kubernetes.io/worker: worker

# –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è worker
frontend:
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi

backend:
  resources:
    requests:
      cpu: 150m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1Gi

# Persistent storage –Ω–∞ worker
persistence:
  enabled: true
  size: 10Gi

ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  hosts:
    - host: kubevious.{self.domain}
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: kubevious-tls
      hosts:
        - kubevious.{self.domain}
'''
        
        with open("/tmp/kubevious-values.yaml", "w") as f:
            f.write(kubevious_values)
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —á–µ—Ä–µ–∑ Helm
        result = subprocess.run([
            "helm", "upgrade", "--install", "kubevious", "kubevious/kubevious",
            "-n", "kubevious", "-f", "/tmp/kubevious-values.yaml"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            if self.wait_for_condition(
                "kubectl -n kubevious rollout status deployment/kubevious --timeout=300s",
                "Kubevious –≥–æ—Ç–æ–≤ –Ω–∞ worker"
            ):
                self.log_success(f"Kubevious —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç –Ω–∞ worker: https://kubevious.{self.domain}")
        else:
            self.log_error(f"–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ Kubevious: {result.stderr}")
    
    def deploy_gpu_monitoring_on_worker(self):
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞ worker (RTX 3090)"""
        self.log_info("–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞ worker...")
        
        gpu_exporter = '''
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-dcgm-exporter
  namespace: monitoring
  labels:
    app: nvidia-dcgm-exporter
spec:
  selector:
    matchLabels:
      app: nvidia-dcgm-exporter
  template:
    metadata:
      labels:
        app: nvidia-dcgm-exporter
    spec:
      nodeSelector:
        node-role.kubernetes.io/worker: "worker"  # –¢–æ–ª—å–∫–æ –Ω–∞ worker —Å GPU
      hostNetwork: true
      containers:
      - name: nvidia-dcgm-exporter
        image: nvcr.io/nvidia/k8s/dcgm-exporter:3.1.8-3.1.5-ubuntu20.04
        env:
        - name: DCGM_EXPORTER_LISTEN
          value: ":9400"
        - name: DCGM_EXPORTER_KUBERNETES
          value: "true"
        resources:
          requests:
            cpu: 50m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 256Mi
        securityContext:
          privileged: true
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      tolerations:
      - operator: Exists  # –ú–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ –ª—é–±—ã—Ö –Ω–æ–¥–∞—Ö
---
apiVersion: v1
kind: Service
metadata:
  name: nvidia-dcgm-exporter
  namespace: monitoring
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9400"
spec:
  selector:
    app: nvidia-dcgm-exporter
  ports:
  - port: 9400
    targetPort: 9400
    name: metrics
'''
        
        with open("/tmp/gpu-monitoring.yaml", "w") as f:
            f.write(gpu_exporter)
        
        self.run_kubectl("apply -f /tmp/gpu-monitoring.yaml", capture_output=False)
        self.log_success("GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –Ω–∞ worker (RTX 3090)")
    
    def deploy_monitoring_on_master(self) -> bool:
        """Fallback: —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏ –Ω–∞ master"""
        self.log_warning("–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞ master —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏...")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –Ω–æ —Å –∂–µ—Å—Ç–∫–∏–º–∏ –ª–∏–º–∏—Ç–∞–º–∏
        monitoring_dir = REPO_ROOT / "manifests/monitoring"
        if monitoring_dir.exists():
            self.run_kubectl(f"apply -k {monitoring_dir}", capture_output=False)
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã –Ω–∞ master
        resource_patches = {
            "prometheus": {
                "requests": {"cpu": "300m", "memory": "512Mi"},
                "limits": {"cpu": "500m", "memory": "1Gi"}
            },
            "grafana": {
                "requests": {"cpu": "100m", "memory": "128Mi"}, 
                "limits": {"cpu": "200m", "memory": "256Mi"}
            }
        }
        
        for app, resources in resource_patches.items():
            patch = {
                "spec": {
                    "template": {
                        "spec": {
                            "containers": [{
                                "name": app,
                                "resources": resources
                            }]
                        }
                    }
                }
            }
            
            self.run_kubectl(f"patch deployment {app} -n monitoring --patch '{json.dumps(patch)}'")
        
        self.log_success("–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç –Ω–∞ master —Å –∂–µ—Å—Ç–∫–∏–º–∏ –ª–∏–º–∏—Ç–∞–º–∏")
        return True
    
    def apply_cluster_issuers(self):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ ClusterIssuer –¥–ª—è TLS —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤"""
        self.log_info("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ ClusterIssuer –¥–ª—è TLS...")
        
        # HTTP-01 issuer
        http01_manifest = REPO_ROOT / "manifests/cert-manager/clusterissuer-http01.yaml"
        if http01_manifest.exists():
            env = os.environ.copy()
            env["ACME_EMAIL"] = self.email
            subprocess.run(f"ACME_EMAIL={self.email} envsubst < {http01_manifest} | kubectl apply -f -", shell=True)
            self.log_success("HTTP-01 ClusterIssuer –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        
        # DNS-01 –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        if self.use_dns01:
            cf_token = os.getenv("CF_API_TOKEN", "")
            if cf_token:
                subprocess.run([
                    "kubectl", "-n", "cert-manager", "create", "secret", "generic", 
                    "cloudflare-api-token", f"--from-literal=api-token={cf_token}",
                    "--dry-run=client", "-o", "yaml"
                ], stdout=subprocess.PIPE)
                
                dns01_manifest = REPO_ROOT / "manifests/cert-manager/clusterissuer-dns01-cloudflare.yaml"
                if dns01_manifest.exists():
                    env = os.environ.copy()
                    env["ACME_EMAIL"] = self.email
                    subprocess.run(f"ACME_EMAIL={self.email} envsubst < {dns01_manifest} | kubectl apply -f -", shell=True)
                    self.log_success("DNS-01 ClusterIssuer –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
    
    def expose_services(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ Ingress –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Å–µ—Ä–≤–∏—Å–∞–º"""
        self.log_info("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Ingress –¥–ª—è —Å–µ—Ä–≤–∏—Å–æ–≤...")
        
        # Grafana Ingress
        grafana_ingress = f'''
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana
  namespace: monitoring
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - grafana.{self.domain}
    secretName: grafana-tls
  rules:
  - host: grafana.{self.domain}
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: grafana
            port:
              number: 3000
'''
        
        with open("/tmp/grafana-ingress.yaml", "w") as f:
            f.write(grafana_ingress)
        
        self.run_kubectl("apply -f /tmp/grafana-ingress.yaml", capture_output=False)
        self.log_success(f"Grafana Ingress: https://grafana.{self.domain}")
    
    def apply_optimizations(self):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π"""
        self.log_info("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π –∫–ª–∞—Å—Ç–µ—Ä–∞...")
        
        # VPA
        core_dir = REPO_ROOT / "manifests/core"
        if core_dir.exists():
            vpa_file = core_dir / "vpa.yaml"
            if vpa_file.exists():
                self.run_kubectl(f"apply -f {vpa_file}", capture_output=False)
                self.log_success("VPA –ø—Ä–∏–º–µ–Ω–µ–Ω")
    
    def perform_smoke_tests(self):
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ smoke —Ç–µ—Å—Ç—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        self.log_info("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ smoke —Ç–µ—Å—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
        
        # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤
        self.log_info("–û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–∏—è TLS —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ (60s)...")
        time.sleep(60)
        
        tests = [
            ("kubectl get nodes -o wide", "–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–¥ –∫–ª–∞—Å—Ç–µ—Ä–∞"),
            ("kubectl -n monitoring get pods", "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–æ–≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"),
            ("kubectl -n kubevious get pods", "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–æ–≤ Kubevious"),
            ("kubectl get certificates --all-namespaces", "–ü—Ä–æ–≤–µ—Ä–∫–∞ TLS —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤"),
            ("kubectl -n monitoring get ingress", "–ü—Ä–æ–≤–µ—Ä–∫–∞ Grafana Ingress"),
            ("kubectl -n kubevious get ingress", "–ü—Ä–æ–≤–µ—Ä–∫–∞ Kubevious Ingress")
        ]
        
        success_count = 0
        for cmd, description in tests:
            if self.wait_for_condition(cmd, description, timeout=60):
                success_count += 1
        
        self.log_info(f"Smoke —Ç–µ—Å—Ç—ã: {success_count}/{len(tests)} –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ URL
        print(f"\nüéâ –†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print(f"\nüìä –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã:")
        print(f"  ‚Ä¢ Grafana:   https://grafana.{self.domain}")
        print(f"  ‚Ä¢ Kubevious: https://kubevious.{self.domain}")
        print(f"\nüîê Grafana credentials: admin/admin (–∏–∑–º–µ–Ω–∏—Ç–µ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—Ö–æ–¥–µ)")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏
        self.show_resource_distribution()
    
    def show_resource_distribution(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –º–µ–∂–¥—É –Ω–æ–¥–∞–º–∏"""
        print(f"\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ù–ê–ì–†–£–ó–ö–ò:")
        print(f"="*50)
        
        if self.worker_nodes:
            print(f"üñ•Ô∏è  Master VPS (3 vCPU, 4GB RAM, 10 Gbps):")
            print(f"  ‚úÖ K3S Control Plane")
            print(f"  ‚úÖ ingress-nginx")
            print(f"  ‚úÖ cert-manager") 
            print(f"  ‚úÖ CoreDNS")
            print(f"  ‚úÖ Metrics Server")
            print(f"  üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: ~23% CPU, ~55% RAM")
            print()
            print(f"üè† Worker Home PC (26 CPU, 64GB RAM, 100 Mbps internet):")
            print(f"  ‚úÖ Prometheus (–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥)")
            print(f"  ‚úÖ Grafana (–¥–∞—à–±–æ—Ä–¥—ã)")
            print(f"  ‚úÖ Kubevious (–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è)")
            print(f"  ‚úÖ Registry Cache")
            if self.enable_gpu:
                print(f"  ‚úÖ GPU Monitoring (RTX 3090)")
            print(f"  üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: ~4% CPU, ~3% RAM")
            print(f"  üì° –°–≤—è–∑—å —Å VPS: ~10 –ú–ë/—Å (Tailscale)")
        else:
            print(f"üñ•Ô∏è  Master VPS (3 vCPU, 4GB RAM, 10 Gbps):")
            print(f"  ‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (—Å –∂–µ—Å—Ç–∫–∏–º–∏ –ª–∏–º–∏—Ç–∞–º–∏)")
            print(f"  üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: ~70% CPU, ~85% RAM")
            print(f"  ‚ö†Ô∏è  –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å worker –Ω–æ–¥—É")
    
    def run_full_deployment(self) -> bool:
        """–ü–æ–ª–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞"""
        print("üöÄ –ó–ê–ü–£–°–ö –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –†–ê–ó–í–ï–†–¢–´–í–ê–ù–ò–Ø K3S –ö–õ–ê–°–¢–ï–†–ê")
        print(f"üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: –¥–æ–º–µ–Ω={self.domain}, GPU={self.enable_gpu}, DNS-01={self.use_dns01}")
        print("="*80)
        
        try:
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
            if not self.check_dependencies():
                return False
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ master
            try:
                self.run_kubectl("cluster-info", timeout=30)
                self.log_success("–ö–ª–∞—Å—Ç–µ—Ä —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            except subprocess.TimeoutExpired:
                self.log_error("–ö–ª–∞—Å—Ç–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –°–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ master –∫–æ–º–∞–Ω–¥–æ–π:")
                self.log_info("python3 scripts/install_cluster_enhanced.py --mode master")
                return False
            except subprocess.CalledProcessError:
                self.log_error("–ö–ª–∞—Å—Ç–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –°–Ω–∞—á–∞–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ master –∫–æ–º–∞–Ω–¥–æ–π:")
                self.log_info("python3 scripts/install_cluster_enhanced.py --mode master")
                return False
            
            # 3. –ê–Ω–∞–ª–∏–∑ —Ç–æ–ø–æ–ª–æ–≥–∏–∏
            if not self.analyze_cluster_topology():
                return False
            
            # 4. –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞ master
            if not self.deploy_master_components():
                return False
            
            # 5. –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞ worker (–∏–ª–∏ master –µ—Å–ª–∏ –Ω–µ—Ç worker)
            if not self.deploy_worker_components():
                return False
            
            # 6. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Å–µ—Ä–≤–∏—Å–∞–º
            self.expose_services()
            
            # 7. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
            self.apply_optimizations()
            
            # 8. –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã
            self.perform_smoke_tests()
            
            return True
            
        except KeyboardInterrupt:
            self.log_warning("–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return False
        except Exception as e:
            self.log_error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            return False

def main():
    parser = argparse.ArgumentParser(description="–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ K3S –∫–ª–∞—Å—Ç–µ—Ä–∞")
    parser.add_argument("--domain", required=True, help="–ë–∞–∑–æ–≤—ã–π –¥–æ–º–µ–Ω, –Ω–∞–ø—Ä–∏–º–µ—Ä cockpit.work.gd")
    parser.add_argument("--email", required=True, help="Email –¥–ª—è ACME Let's Encrypt")
    parser.add_argument("--gpu", default="true", choices=["true", "false"], help="–í–∫–ª—é—á–∏—Ç—å GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
    parser.add_argument("--dns01", action="store_true", help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DNS-01 (Cloudflare) –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω CF_API_TOKEN")
    
    args = parser.parse_args()
    
    deployer = OptimizedClusterDeployer(
        domain=args.domain,
        email=args.email,
        enable_gpu=args.gpu.lower() == "true",
        use_dns01=args.dns01
    )
    
    success = deployer.run_full_deployment()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()